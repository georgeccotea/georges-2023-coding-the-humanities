{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV-UrkvK3HBQ"
   },
   "source": [
    "# Files: Graded assignment\n",
    "This notebook contains the third graded collaborative assignment of the 2023 Coding the Humanities course, and it is based on the [4. Reading And Writing Files](../../4_ReadingAndWritingFiles.ipynb) course material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13WY-Pd4m1Nq"
   },
   "source": [
    "This is a collaborative assignment. In the text cell below, please include all the names of your group members.\n",
    "\n",
    "Below that, answer the question using a mix of code cells and text cells in a way that would make your answers understandable to outsiders. To explain your code, you can use commenting (#) and/or text cells, similar to what you see in the course materials.\n",
    "\n",
    "If you used code or a solution from the internet (such as StackOverflow) or another external resource, please make reference to it (in any format). Unattributed copied code will be considered plagiarism and therefore fraud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors of this answer: George Raluca Ruben Nadia **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVxv8FjzoS_w",
    "tags": []
   },
   "source": [
    "# Assignment\n",
    "\n",
    "In the Data directory, you will find four snippets of texts by the philosopher Willard Quine, on various topics. We will do some file reading (and writing) to analyse these.\n",
    "\n",
    "Please use functions and function documentation where applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file *quine_elementarylogic_denial.txt* explains some basics of logic. Usually some empty space is left after logical formulae.\n",
    "\n",
    "1. From the file *quine_elementarylogic_denial.txt*, print only the lines that are not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denial\n",
      "Given any statement, we can form another by denying the first. The resulting denial is false or true according as the original statement is true or false. The denial of a statement will be written by putting the statement in question in the blank of '~(\t)''; but\n",
      "the parentheses will be suppressed unless the statement within them is a conjunction. Thus the denial of 'Kansas touches Iowa'' is:\n",
      "(1)\t~ Kansas touches Iowa, and the denial of §3(1) is:\n",
      "(2)\t~(Jones is ill. Smith is away).\n",
      "The tilde '~'' is a modified 'n'' and is conveniently read 'not''.\n",
      "The method of forming the denial in ordinary language is irregular. Sometimes 'not'' or 'does not'' or 'fails to'' is applied to the main verb; thus (1) might appear in words as 'Kansas does not touch Iowa'', or 'Kansas fails to touch Iowa''. If the statement has no one main verb, denial is accomplished by one or another periphrasis; e.g., the denial (2) might be rendered in words thus:\n",
      "(3)\tIt is not the case that Jones is ill and Smith is away.\n"
     ]
    }
   ],
   "source": [
    "# Opening the quine_elementarylogic_denial.txt file\n",
    "quine_elementarylogic_denial = open(\"data/quine_elementarylogic_denial.txt\", \"r\")\n",
    "# Reading the file\n",
    "quineContent = quine_elementarylogic_denial.read()\n",
    "# Splitting the file into lines\n",
    "quineLines = quine_elementarylogic_denial_content.split(\"\\n\")\n",
    "# Printing the lines that are not empty\n",
    "for line in quineLines:\n",
    "    if line != \"\":\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For the same file, calculate the percentage of lines that is not empty. To do this, you'll need the total number of lines and the number of non-empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denial\n",
      "\n",
      "\n",
      "\n",
      "Given any statement, we can form another by denying the first. The resulting denial is false or true according as the original statement is true or false. The denial of a statement will be written by putting the statement in question in the blank of '~(\t)''; but\n",
      "\n",
      "\n",
      "\n",
      "the parentheses will be suppressed unless the statement within them is a conjunction. Thus the denial of 'Kansas touches Iowa'' is:\n",
      "\n",
      "\n",
      "\n",
      "(1)\t~ Kansas touches Iowa, and the denial of §3(1) is:\n",
      "\n",
      "\n",
      "\n",
      "(2)\t~(Jones is ill. Smith is away).\n",
      "\n",
      "\n",
      "\n",
      "The tilde '~'' is a modified 'n'' and is conveniently read 'not''.\n",
      "\n",
      "\n",
      "\n",
      "The method of forming the denial in ordinary language is irregular. Sometimes 'not'' or 'does not'' or 'fails to'' is applied to the main verb; thus (1) might appear in words as 'Kansas does not touch Iowa'', or 'Kansas fails to touch Iowa''. If the statement has no one main verb, denial is accomplished by one or another periphrasis; e.g., the denial (2) might be rendered in words thus:\n",
      "\n",
      "\n",
      "\n",
      "(3)\tIt is not the case that Jones is ill and Smith is away.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "34\n",
      "23.52941176470588\n"
     ]
    }
   ],
   "source": [
    "# Opening the quine_elementarylogic_denial.txt file\n",
    "quine_elementarylogic_denial = open(\"data/quine_elementarylogic_denial.txt\", \"r\")\n",
    "# Reading the file\n",
    "quine_elementarylogic_denial_stuff = quine_elementarylogic_denial.read()\n",
    "# Splitting the file into lines\n",
    "quine_elementarylogic_denial_lines = quine_elementarylogic_denial_stuff.split(\"\\n\")\n",
    "# Counting the number of non-empty lines\n",
    "non_empty_lines = 0\n",
    "all_lines = len(quine_elementarylogic_denial_lines)\n",
    "for line in quine_elementarylogic_denial_lines:\n",
    "    if line != \"\":\n",
    "        non_empty_lines += 1\n",
    "\n",
    "print(non_empty_lines)\n",
    "print(all_lines)\n",
    "# Calculating the percentage of non-empty lines\n",
    "percentage_non_empty_lines = non_empty_lines / all_lines * 100\n",
    "print(percentage_non_empty_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the four text files contains paragraph markers in XML format, which enclose a paragraph. They look like this: `<p> </p>`. Find out which file it is (you do not need to use Python code for that). \n",
    "\n",
    "3. Create a version of the text without those markers. We would like it to be in the directory named 'out' to avoid overwriting the original file. You can do this by first reading the text file, using Python to remove the markers from the text, and then writing the text to a new file in the 'out' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8LSmnXOtm5sg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quine_naturalknowledge_1975.txt\n"
     ]
    }
   ],
   "source": [
    "# Iterating through the data folder to check which file contains paragraph markers\n",
    "import os\n",
    "for file in os.listdir(\"data\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(\"data/\" + file, \"r\") as f:\n",
    "            content = f.read()\n",
    "            if \"<p>\" in content:\n",
    "                print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<P> DOUBT has oft been said to be the mother of philosophy. This has a true ring for those of us who look upon philosophy primarily as the theory of knowledge. For the theory of knowledge has its origin in doubt, in scepticism. Doubt is what prompts us to try to develop a theory of knowledge. Furthermore, doubt is also the first step to take in developing a theory of knowledge, if we adopt the line of Descartes. \n",
      "   But this is only half of a curious interplay between doubt and knowledge. Doubt prompts the theory of knowledge, yes; but knowledge, also, was what prompted the doubt. Scepticism is an offshoot of science. The basis for scepticism is the awareness of illusion, the discovery that we must not always believe our eyes. Scepticism battens on mirages, on seemingly bent sticks in water, on rainbows, after-images, double images, dreams. But in what sense are these illusions? In the sense that they seem to be material objects which they in fact are not. Illusions are illusions only relative to a prior acceptance of genuine bodies with which to contrast them. In a world of immediate sense data with no bodies posited and no questions asked, a distinction between reality and illusion would have no place. The positing of bodies is already rudimentary physical science; and it is only after that stage that the sceptic’s invidious distinctions can make sense. Bodies have to be posited before there can be a motive, however tenuous, for acquiescing in a non-committal world of the immediate given. \n",
      "   Rudimentary physical science, that is, common sense about bodies, is thus needed as a springboard for scepticism. It contributes the needed notion of a distinction between reality and illusion, and that is not all. It also discerns regularities of bodily behaviour which are indispensable to that distinction. The sceptic’s example of the seemingly bent stick owes its force to our knowledge that sticks do not bend by immersion; and his examples of mirages, after-images, dreams, and the rest are similarly parasitic upon positive science, however primitive. \n",
      "   I am not accusing the sceptic of begging the question. He is quite within his rights in assuming science in order to refute science; this, if carried out, would be a straightforward argument by reductio ad absurdum. I am only making the point that sceptical doubts are scientific doubts. \n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opening the XML file and removing the paragraph markers\n",
    "xmlFile = open(\"data/quine_naturalknowledge_1975.txt\", \"r\")\n",
    "xmlContent = xmlFile.read()\n",
    "xmlContent = xmlContent.replace(\"<p>\", \"\")\n",
    "xmlContent = xmlContent.replace(\"</p>\", \"\")\n",
    "print (xmlContent)\n",
    "# Writing the new file in the out folder\n",
    "newFile = open(\"out/quine_de_xmld_naturalknowledge_1975.txt\", \"w\")\n",
    "newFile.write(xmlContent)\n",
    "newFile.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a function that can compute the total number of words in all files in a directory, returning a single number. Apply it to the 'data' directory to get the number of words in all 4 files combined, and print the number. Use the NLTK tokenizer that was shown in this week's notebook for optimal results. For this question, don't worry too much about what exactly is a 'word', but if you can remove punctuation from the count somehow, that is nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1634"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function that counts the number of words in a all files in a directory\n",
    "import os\n",
    "import nltk\n",
    "def count_words(directory):\n",
    "    '''\n",
    "    This function counts the number of words in all files in a directory.\n",
    "    :param directory: the directory where the files are located\n",
    "    :return: the total number of words in all files in the directory\n",
    "    '''\n",
    "    # Initializing the total number of words\n",
    "    total_words = 0\n",
    "    # Iterating through the files in the directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(directory + \"/\" + file, \"r\") as f:\n",
    "                content = f.read()\n",
    "                words = word_tokenize(content)\n",
    "                total_words += len(words)\n",
    "    return total_words\n",
    "# Applying the function to the data directory\n",
    "count_words(\"data\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2-Weekly-Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
